/*
 * Copyright Institute for Theoretical Physics, ETH Zurich 2015.
 * Distributed under the Boost Software License, Version 1.0.
 *
 * Permission is hereby granted, free of charge, to any person or organization
 * obtaining a copy of the software and accompanying documentation covered by
 * this license (the "Software") to use, reproduce, display, distribute,
 * execute, and transmit the Software, and to prepare derivative works of the
 * Software, and to permit third-parties to whom the Software is furnished to
 * do so, all subject to the following:
 *
 * The copyright notices in the Software and this entire statement, including
 * the above license grant, this restriction and the following disclaimer,
 * must be included in all copies of the Software, in whole or in part, and
 * all derivative works of the Software, unless such copies or derivative
 * works are solely in the form of machine-executable object code generated by
 * a source language processor.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
 * SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
 * FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 */

#ifndef BIND
#define BIND
#ifndef NDEBUG
#define NDEBUG
#define BIND_NO_DEBUG
#endif
// {{{ system includes
#ifdef BIND_MPI
#include <mpi.h>
#endif
#include <complex>
#include <stdio.h>
#include <stdlib.h>
#include <assert.h>
#include <string>
#include <limits>
#include <vector>
#include <stack>
#include <set>
#include <map>
#include <list>
#include <memory.h>
#include <stdarg.h>
#include <ctype.h>
#include <iostream>
#include <fstream>
#include <sys/time.h>
#include <algorithm>
#include <execinfo.h>
#include <stdexcept>
#include <type_traits>
#include <functional>
#include <utility>
#include <atomic>
#include <tuple>
#include <sys/mman.h>
#include <chrono>
#include <cilk/cilk.h>
#include <cilk/cilk_api.h>
// }}}
// {{{ utils package
#ifndef UTILS_GET_RSS_HPP
#define UTILS_GET_RSS_HPP


#if defined(__unix__) || defined(__unix) || defined(unix) || (defined(__APPLE__) && defined(__MACH__))
#include <unistd.h>
#include <sys/resource.h>

#if defined(__APPLE__) && defined(__MACH__)
#include <mach/mach.h>

#elif (defined(_AIX) || defined(__TOS__AIX__)) || (defined(__sun__) || defined(__sun) || defined(sun) && (defined(__SVR4) || defined(__svr4__)))
#include <fcntl.h>
#include <procfs.h>

#elif defined(__linux__) || defined(__linux) || defined(linux) || defined(__gnu_linux__)
#include <stdio.h>

#endif

#else
#error "Cannot define getPeakRSS( ) or getCurrentRSS( ) for an unknown OS."
#endif

inline size_t getRSSLimit(){
#if defined(__APPLE__) && defined(__MACH__)
    return 0L;

#elif defined(__linux__) || defined(__linux) || defined(linux) || defined(__gnu_linux__)
    long pages = sysconf(_SC_PHYS_PAGES);
    long page_size = sysconf(_SC_PAGE_SIZE);
    return pages * page_size;
#else
    return (size_t)0L;
#endif
    
}

inline size_t getPeakRSS( )
{
#if (defined(_AIX) || defined(__TOS__AIX__)) || (defined(__sun__) || defined(__sun) || defined(sun) && (defined(__SVR4) || defined(__svr4__)))
    struct psinfo psinfo;
    int fd = -1;
    if ( (fd = open( "/proc/self/psinfo", O_RDONLY )) == -1 )
        return (size_t)0L;
    if ( read( fd, &psinfo, sizeof(psinfo) ) != sizeof(psinfo) )
    {
        close( fd );
        return (size_t)0L;
    }
    close( fd );
    return (size_t)(psinfo.pr_rssize * 1024L);

#elif defined(__unix__) || defined(__unix) || defined(unix) || (defined(__APPLE__) && defined(__MACH__))
    struct rusage rusage;
    getrusage( RUSAGE_SELF, &rusage );
#if defined(__APPLE__) && defined(__MACH__)
    return (size_t)rusage.ru_maxrss;
#else
    return (size_t)(rusage.ru_maxrss * 1024L);
#endif

#else
    return (size_t)0L;
#endif
}

inline size_t getCurrentRSS( )
{
#if defined(__APPLE__) && defined(__MACH__)
    struct mach_task_basic_info info;
    mach_msg_type_number_t infoCount = MACH_TASK_BASIC_INFO_COUNT;
    if ( task_info( mach_task_self( ), MACH_TASK_BASIC_INFO,
                (task_info_t)&info, &infoCount ) != KERN_SUCCESS )
        return (size_t)0L;
    return (size_t)info.resident_size;

#elif defined(__linux__) || defined(__linux) || defined(linux) || defined(__gnu_linux__)
    long rss = 0L;
    FILE* fp = NULL;
    if ( (fp = fopen( "/proc/self/statm", "r" )) == NULL )
        return (size_t)0L;
    if ( fscanf( fp, "%*s%ld", &rss ) != 1 )
    {
        fclose( fp );
        return (size_t)0L;
    }
    fclose( fp );
    return (size_t)rss * (size_t)sysconf( _SC_PAGESIZE);

#else
    return (size_t)0L;
#endif
}

#endif
#ifndef STD_INDEX_SEQUENCE
#define STD_INDEX_SEQUENCE

namespace std {

    template<size_t... Indices>
    struct index_sequence {
        template<size_t N>
        using append = index_sequence<Indices..., N>;
    };

    template<size_t Size>
    struct make_index_sequence_impl {
        typedef typename make_index_sequence_impl<Size-1>::type::template append<Size-1> type;
    };

    template<>
    struct make_index_sequence_impl<0u> {
        typedef index_sequence<> type;
    };

    template<size_t Size>
    using make_index_sequence = typename make_index_sequence_impl<Size>::type;

}

#endif

#ifndef BIND_IO
#define BIND_IO

namespace bind { namespace utils {

    class funneled_io {
    public:
        funneled_io() : nullio("/dev/null"), latch(NULL) { }
       ~funneled_io(){
            disable();
        }
        void enable(){
            latch = std::cout.rdbuf();
            std::cout.rdbuf(nullio.rdbuf());
        }
        void disable(){
            if(!latch) return;
            std::cout.rdbuf(latch);
            latch = NULL;
        }
    private:
        std::ofstream nullio;
        std::streambuf* latch;
    };

} }

#endif

#ifndef BIND_UTILS_MUTEX
#define BIND_UTILS_MUTEX

namespace bind { 

    class guard_once {
    public:
        guard_once() : once(false) { }
        bool operator()(){ if(!once){ once = true; return true; } return false; }
    private:
        bool once;
    };

    template <typename M>
    class guard {
    private:
        M& mtx;
        guard(const guard &);
        void operator= (const guard &);
    public:
        explicit guard(M& nmtx) : mtx(nmtx){ mtx.lock(); }
        ~guard(){ mtx.unlock(); }
    };

    class mutex {
    private:
        pthread_mutex_t m;
    public:
        mutex(mutex const&) = delete;
        mutex& operator= (mutex const&) = delete;

        mutex(){
            int const res = pthread_mutex_init(&m,NULL);
            assert(res == 0);
        }
       ~mutex(){
            int ret;
            do{ ret = pthread_mutex_destroy(&m);
            } while(ret == EINTR);
        }
        void lock(){
            int res;
            do{ res = pthread_mutex_lock(&m);
            }while (res == EINTR);
            assert(res == 0);
        }
        void unlock(){
            int res;
            do{ res = pthread_mutex_unlock(&m);
            } while(res == EINTR);
            assert(res == 0);
        }
        bool try_lock(){
            int res;
            do{ res = pthread_mutex_trylock(&m);
            } while(res == EINTR);
            if(res == EBUSY) return false;
            return !res;
        }
    };
}

#endif

#ifndef BIND_UTILS_RANK_TYPE
#define BIND_UTILS_RANK_TYPE

namespace bind {
    #if 0
    class rank_t {
    public:
        rank_t(){}
        rank_t(int r) : rank(r) {}
        bool operator != (const rank_t& other) const { return (rank != other.rank); }
        bool operator == (const rank_t& other) const { return (rank == other.rank); }
        bool operator <  (const rank_t& other) const { return (rank < other.rank);  }
        bool operator >  (const rank_t& other) const { return (rank > other.rank);  }
        int& toint() const { return rank; }
        mutable int rank; // mutable due to MPI
    };
    #else
    typedef int rank_t;
    #endif
}

#endif
// }}}
// {{{ memory package

#ifndef BIND_MEMORY_TYPES
#define BIND_MEMORY_TYPES

namespace bind { namespace memory {

    namespace cpu {
        class standard;
        class bulk;
    }
    class delegated;

    struct memory_tuple {
        typedef std::tuple< memory::cpu::bulk,
                            memory::cpu::standard,
                            memory::delegated > type;
    };

    template<int N, int Limit>
    constexpr int lower_bound(){
        return (N > Limit ? N : Limit);
    }

    template<class T, class Tuple, int I = std::tuple_size<Tuple>::value>
    constexpr int find_type(){
        return I ? std::is_same< typename std::tuple_element<lower_bound<I-1,0>(),Tuple>::type, T >::value ? I-1 : find_type<T,Tuple,lower_bound<I-1,0>()>()
                 : -1;
    }

    template<int Offset>
    struct checked_get { static constexpr int value = Offset; };

    template<>
    struct checked_get< -1 > { /* type not found */ };

    template<typename T>
    constexpr int serial_id(){
        return checked_get< find_type<T,memory_tuple::type>() >::value;
    }
} }

#endif

#ifndef BIND_MEMORY_FACTORY
#define BIND_MEMORY_FACTORY

namespace bind { namespace memory {

    template<size_t S>
    class private_factory {
    public:
        private_factory(){
            this->buffers.push_back(std::malloc(S));
            this->buffer = &this->buffers[0];
        }
       ~private_factory(){
            for(int i = 0; i < buffers.size(); i++) 
                std::free(this->buffers[i]);
        }
        void* provide(){
            void* chunk = *buffer;
            if(chunk == buffers.back()){
                buffers.push_back(std::malloc(S));
                buffer = &buffers.back();
            }else
                buffer++;
            return chunk;
        }
        void reset(){
            buffer = &buffers[0];
        }
        size_t size(){
            return (buffer - &buffers[0]);
        }
    private:
        std::vector<void*> buffers;
        void** buffer;
    };

    template<size_t S>
    class factory {
    public:
        typedef bind::mutex mutex;
        typedef bind::guard<mutex> guard;
    private:
        factory(const factory&) = delete;
        factory& operator=(const factory&) = delete;
        factory(){
            this->buffers.push_back(std::malloc(S));
            this->buffer = &this->buffers[0];
        }
    public:
        static factory& instance(){
            static factory singleton; return singleton;
        }
        static void* provide(){
            factory& s = instance();
            guard g(s.mtx);
            void* chunk;

            chunk = *s.buffer;
            if(*s.buffer == s.buffers.back()){
                s.buffers.push_back(std::malloc(S));
                s.buffer = &s.buffers.back();
            }else
                s.buffer++;

            return chunk;
        }
        static void deallocate(){
            factory& s = instance();
            for(int i = 1; i < s.buffers.size(); i++) std::free(s.buffers[i]);
            s.buffers.resize(1);
        }
        static void reset(){
            factory& s = instance();
            s.buffer = &s.buffers[0];
        }
        static size_t size(){
            factory& s = instance();
            return (s.buffer - &s.buffers[0]);
        }
    private:
        mutex mtx;
        std::vector<void*> buffers;
        void** buffer;
    };

} }

#endif

#ifndef BIND_MEMORY_REGION
#define BIND_MEMORY_REGION

namespace bind { namespace memory {

    constexpr size_t aligned_64(size_t size){ return 64 * (size_t)((size+63)/64); }
    template<size_t S> constexpr size_t aligned_64(){ return 64 * (size_t)((S+63)/64); }

    template<size_t S, class Factory>
    class serial_region {
    public:
        serial_region(){
            this->buffer = NULL;
            this->iterator = (char*)this->buffer+S;
        }
        void realloc(){
            this->buffer = Factory::provide();
            this->iterator = (char*)this->buffer;
        }
        void* malloc(size_t sz){
            if(((size_t)iterator + sz - (size_t)this->buffer) >= S) realloc();
            void* m = (void*)iterator;
            iterator += aligned_64(sz);
            return m;
        }
        void reset(){
            this->iterator = (char*)this->buffer+S;
        }
    protected:
        void* buffer;
        char* iterator;
    };

    template<size_t S, class Factory>
    class private_region : public serial_region<S,Factory> {
    public:
        typedef serial_region<S,Factory> base;
        void* malloc(size_t sz){
            if(((size_t)this->iterator + sz - (size_t)this->buffer) >= S){
                this->buffer = pool.provide();
                this->iterator = (char*)this->buffer;
            }
            void* m = (void*)this->iterator;
            this->iterator += aligned_64(sz);
            return m;
        }
        void reset(){
            base::reset();
            pool.reset();
        }
    private:
        Factory pool;
    };

    template<size_t S, class Factory>
    class region : public serial_region<S,Factory> {
    public:
        typedef bind::mutex mutex;
        typedef bind::guard<mutex> guard;
        typedef serial_region<S,Factory> base;

        void* malloc(size_t sz){
            guard g(this->mtx);
            return base::malloc(sz);
        }
    private:
        mutex mtx;
    };

} }

#endif
    // {{{ memory::cpu package

#ifndef BIND_MEMORY_CPU_BULK_H
#define BIND_MEMORY_CPU_BULK_H

#ifndef BIND_INSTR_BULK_CHUNK
#define BIND_INSTR_BULK_CHUNK     16777216 // 16 MB
#endif
#ifndef BIND_DATA_BULK_CHUNK
#define BIND_DATA_BULK_CHUNK      67108864 // 64 MB
#endif
#ifndef BIND_COMM_BULK_CHUNK
#define BIND_COMM_BULK_CHUNK      67108864 // 64 MB
#endif

namespace bind { namespace memory { namespace cpu {

    class bulk {
        bulk(const bulk&) = delete;
        bulk& operator=(const bulk&) = delete;
    protected:
        bulk() = default;
    public:
        static constexpr int signature = serial_id<cpu::bulk>();
    };

} } }

#endif

#ifndef BIND_MEMORY_CPU_DATA_BULK
#define BIND_MEMORY_CPU_DATA_BULK

#define DATA_BULK_LIMIT 10

namespace bind { namespace memory { namespace cpu {

    class data_bulk : public bulk {
        data_bulk(){
            this->soft_limit = DATA_BULK_LIMIT * ((double)getRSSLimit() / BIND_DATA_BULK_CHUNK / 100);
        }
    public:
        static data_bulk& instance(){
            static data_bulk singleton; return singleton;
        }
        static void* soft_malloc(size_t s){
            if(instance().soft_limit < factory<BIND_DATA_BULK_CHUNK>::size() || s > BIND_DATA_BULK_CHUNK) return NULL;
            return instance().memory.malloc(s);
        }

        static void drop(){
            instance().memory.reset();
            if(instance().soft_limit < factory<BIND_DATA_BULK_CHUNK>::size())
                factory<BIND_DATA_BULK_CHUNK>::deallocate();
            factory<BIND_DATA_BULK_CHUNK>::reset();
        }
    private:
        region<BIND_DATA_BULK_CHUNK, factory<BIND_DATA_BULK_CHUNK> > memory;
        size_t soft_limit;
    };

} } }

#undef DATA_BULK_LIMIT
#endif

#ifndef BIND_MEMORY_CPU_COMM_BULK
#define BIND_MEMORY_CPU_COMM_BULK

#define COMM_BULK_LIMIT 20

namespace bind { namespace memory { namespace cpu {

    class comm_bulk : public bulk {
        comm_bulk(){
            this->soft_limit = COMM_BULK_LIMIT * ((double)getRSSLimit() / BIND_COMM_BULK_CHUNK / 100);
        }
    public:
        static comm_bulk& instance(){
            static comm_bulk singleton; return singleton;
        }
        template<size_t S> static void* malloc()        { return instance().memory.malloc(S); }
                           static void* malloc(size_t s){ return instance().memory.malloc(s); }
        static void drop(){
            instance().memory.reset();
            if(instance().soft_limit < factory<BIND_COMM_BULK_CHUNK>::size())
                factory<BIND_COMM_BULK_CHUNK>::deallocate();
            factory<BIND_COMM_BULK_CHUNK>::reset();
        }
    private:
        size_t soft_limit;
        region<BIND_COMM_BULK_CHUNK, factory<BIND_COMM_BULK_CHUNK> > memory;
    };

} } }

#undef COMM_BULK_LIMIT
#endif

#ifndef BIND_MEMORY_CPU_INSTR_BULK_H
#define BIND_MEMORY_CPU_INSTR_BULK_H

namespace bind { namespace memory { namespace cpu {

    struct instr_bulk {
        template<class T>
        class allocator {
        public:
            typedef T value_type;
            template <class U> struct rebind { typedef allocator<U> other; };
            allocator() throw() { }
            allocator(const allocator&) throw() { }
            template<typename U> allocator(const allocator<U>&) throw() { }
           ~allocator() throw() { }
            static void deallocate(T* p, size_t n){ }
            static T* allocate(size_t n){
                return (T*)instr_bulk::malloc(n*sizeof(T));
            }
        };

        static instr_bulk& instance(){
            static instr_bulk singleton; return singleton;
        }
        template<size_t S> 
        static void* malloc(){
            return malloc(S);
        }
        static void* malloc(size_t s){
            return instance().impl.malloc(s);
        }
        static void drop(){
            instance().impl.reset();
        }
    private:
        memory::private_region<BIND_INSTR_BULK_CHUNK, 
                               memory::private_factory<BIND_INSTR_BULK_CHUNK> 
                              > impl;
    };

} } }

#endif


#ifndef BIND_MEMORY_CPU_STANDARD_HPP
#define BIND_MEMORY_CPU_STANDARD_HPP

namespace bind { namespace memory { namespace cpu {

    struct standard {
        static void* malloc(size_t sz){ return std::malloc(sz); }
        static void free(void* ptr){ std::free(ptr);  }
        static constexpr int signature = serial_id<cpu::standard>();
    };

} } }

#endif

#ifndef BIND_MEMORY_CPU_FIXED_HPP
#define BIND_MEMORY_CPU_FIXED_HPP

namespace bind { namespace memory { namespace cpu {

    struct fixed {
        // boost::singleton_pool<fixed,S> can be used instead (implicit mutex)
        template<size_t S> static void* malloc(){ return std::malloc(S);   }
        template<size_t S> static void* calloc(){ return std::calloc(1,S); }
        static void free(void* ptr){ std::free(ptr);    }
    };

} } }

#endif

#ifndef BIND_MEMORY_CPU_NEW
#define BIND_MEMORY_CPU_NEW

namespace bind { namespace memory { namespace cpu {

    template<class T>
    class use_fixed_new {
    public:
        void* operator new (size_t sz){ assert(sz == sizeof(T)); return memory::cpu::fixed::malloc<sizeof(T)>(); }
        void operator delete (void* ptr){ memory::cpu::fixed::free(ptr); }
    };

    template<class T>
    class use_bulk_new {
    public:
        void* operator new (size_t sz){ assert(sz == sizeof(T)); return memory::cpu::instr_bulk::malloc<sizeof(T)>(); }
        void operator delete (void* ptr){ }
    };

} } }

#endif
    // }}}
    // {{{ memory::gpu package
    // }}}

#ifndef BIND_MEMORY_DELEGATED_H
#define BIND_MEMORY_DELEGATED_H

namespace bind { namespace memory {

    class delegated {
    public:
        static constexpr int signature = serial_id<delegated>();
    };

} }

#endif

#ifndef BIND_MEMORY_DESCRIPTOR
#define BIND_MEMORY_DESCRIPTOR

namespace bind { namespace memory {

    struct descriptor {
        typedef int memory_id_type;

        descriptor(size_t e, memory_id_type r = cpu::standard::signature) : extent(e), signature(r), persistency(1), crefs(1) {}

        void protect(){
            if(!(persistency++)) signature = cpu::standard::signature;
        }
        void weaken(){
            if(!(--persistency)) signature = cpu::bulk::signature;
        }
        void reuse(descriptor& d){
            signature = d.signature;
            d.signature = delegated::signature;
        }
        bool conserves(descriptor& p){
            assert(p.signature != delegated::signature && signature != delegated::signature);
            return (!p.bulked() || bulked());
        }
        bool bulked(){
            return (signature == cpu::bulk::signature);
        }
        void* malloc(){
            assert(signature != delegated::signature);
            if(signature == cpu::bulk::signature){
                void* ptr = cpu::data_bulk::soft_malloc(extent);
                if(ptr) return ptr;
                signature = cpu::standard::signature;
            }
            return cpu::standard::malloc(extent);
        }
        template<class Memory>
        void* hard_malloc(){
            signature = Memory::signature;
            return Memory::malloc(extent);
        }
        void free(void* ptr){ 
            if(ptr == NULL || signature == delegated::signature) return;
            if(signature == cpu::standard::signature) cpu::standard::free(ptr);
        }

        size_t extent;
        memory_id_type signature;
        int persistency;
        int crefs;
    };

} }

#endif
// }}}
// {{{ model package

#ifndef BIND_MODEL_LOCALITY
#define BIND_MODEL_LOCALITY

namespace bind {
    enum class locality { remote, local, common };
}

#endif

#ifndef BIND_MODEL_FUNCTOR
#define BIND_MODEL_FUNCTOR

namespace bind { namespace model {
    
    class functor {
        typedef memory::cpu::instr_bulk::allocator<functor*> allocator_type;
    public:
        virtual void invoke() = 0;
        virtual bool ready() = 0;
        void queue(functor* d){ deps.push_back(d); }
        std::vector<functor*, allocator_type> deps;
        void* arguments[1]; // note: trashing the vtptr of derived object
    };

} }

#endif

#ifndef BIND_MODEL_REVISION
#define BIND_MODEL_REVISION

namespace bind { namespace model {

    class revision : public memory::cpu::use_fixed_new<revision> {
    public:
        template<typename T> operator T* (){ return (T*)data; }
        operator revision* (){ return NULL; }

        revision(size_t extent, functor* g, locality l, rank_t owner)
        : spec(extent), generator(g), state(l), 
          data(NULL), users(0), owner(owner)
        {
        }

        void embed(void* ptr){
            data = ptr;
        }

        void reuse(revision& r){
            data = r.data;
            spec.reuse(r.spec);
        }

        void use(){
            ++users;
        }

        void release(){
            --users;
        }

        void complete(){
            generator = NULL;
        }

        void invalidate(){
            data = NULL;
        }

        bool locked() const {
            return (users != 0);
        }

        bool locked_once() const {
            return (users == 1);
        }

        bool valid() const {
            return (data != NULL);
        }

        bool referenced() const {
            return (spec.crefs != 0);
        }

        std::atomic<functor*> generator;
        void* data;
        rank_t owner;
        std::atomic<int> users;
        locality state;
        std::pair<size_t, functor*> assist;
        memory::descriptor spec;
    };

    inline bool local(const revision* r){
        return (r->state == locality::local);
    }
    
    inline bool remote(const revision* r){
        return (r->state == locality::remote);
    }
    
    inline bool common(const revision* r){
        return (r->state == locality::common);
    }
    
    inline rank_t owner(const revision* r){
        return r->owner;
    }

} }

#endif

#ifndef BIND_MODEL_HISTORY
#define BIND_MODEL_HISTORY

// revision tracking mechanism (target selector)
namespace bind { namespace model {

    class history : public memory::cpu::use_fixed_new<history> {
    public:
        history(size_t size) : current(NULL), extent(memory::aligned_64(size)) { }
        void init_state(rank_t owner){
            revision* r = new revision(extent, NULL, locality::common, owner);
            this->current = r;
        }
        template<locality L> void add_state(functor* gen, rank_t owner){
            revision* r = new revision(extent, gen, L, owner);
            this->current = r;
        }
        revision* back() const {
            return this->current;
        }
        bool weak() const {
            return (this->back() == NULL);
        }
        revision* current;
        size_t extent;
    };

} }

#endif

#ifndef BIND_MODEL_ANY
#define BIND_MODEL_ANY

namespace bind { namespace model {

    template<typename T>
    constexpr size_t sizeof_any(){
        return (2*sizeof(void*) + sizeof(size_t) + memory::aligned_64<sizeof(T)>());
    }

    class any {
    public:
        // WARNING: the correct allocation of sizeof_any required
        void* operator new (size_t, void* place){ return place; }
        void operator delete (void*, void*){}

        template<typename T>
        any(T val) : size(memory::aligned_64<sizeof(T)>()) { *this = val; }
        template<typename T> void operator = (T val){ *(T*)&value = val; }
        template<typename T> operator T& (){ return *(T*)&value;  }
        void complete(){ generator = NULL; }

        functor* generator;
        any* origin;
        size_t size;
        int value;
    };

} }

#endif
// }}}
// {{{ transport package (requires :model)
#ifdef BIND_MPI
#define BIND_CHANNEL_NAME mpi

#ifndef BIND_TRANSPORT_MPI_GROUP
#define BIND_TRANSPORT_MPI_GROUP

namespace bind { namespace transport { namespace mpi {

    struct group {
        group(MPI_Comm parent) : mpi_comm(parent)
        {
            MPI_Comm_group(this->mpi_comm,  &this->mpi_group);
            MPI_Group_size(this->mpi_group, &this->size);
            MPI_Group_rank(this->mpi_group, &this->rank);
        }
        int rank;
        int size;
        MPI_Comm  mpi_comm;
        MPI_Group mpi_group;
    };

} } }

#endif

#ifndef BIND_TRANSPORT_MPI_TREE
#define BIND_TRANSPORT_MPI_TREE

#define BOUNDARY_OVERFLOW -1

namespace bind {

    template<typename T>
    class binary_tree {
    public:
        binary_tree(size_t N) : tree(N), length(N) {
            entry_point = N/2;
            generate(tree, N, N);
            normalize();
            check();
        }
        T generate(std::vector<std::pair<T,T> >& tree, int N, int L, int start = 0){
            if(N <= 0 || start >= L) return BOUNDARY_OVERFLOW;
            tree[start+N/2] = std::make_pair(generate(tree, N/2, L, start), 
                                             generate(tree, N-N/2-1, L, start+N/2+1));
            return start+N/2;
        }
        void normalize(){
            std::vector<std::pair<T,T> > normalized(length);
            for(int i = 0; i < length; i++){
                normalized[i] = tree[(i+entry_point)%length];
                if(normalized[i].first  != BOUNDARY_OVERFLOW) normalized[i].first  = (normalized[i].first  - entry_point + length) % length;
                if(normalized[i].second != BOUNDARY_OVERFLOW) normalized[i].second = (normalized[i].second - entry_point + length) % length;
            }
            std::swap(tree, normalized);
            entry_point = 0;
        }
        void check(){
            std::vector<bool> states(length);
            for(int i = 0; i < length; i++){
                if(tree[i].first  != BOUNDARY_OVERFLOW) states[tree[i].first]  = true;
                if(tree[i].second != BOUNDARY_OVERFLOW) states[tree[i].second] = true;
            }
            for(int i = 0; i < length; i++){
                if(!states[i] && i != entry_point) throw std::runtime_error("Error: no route to host");
            }
        }
        std::pair<T,T> operator[](int i) const {
            return tree[i];
        }
    private:
        std::vector<std::pair<T,T> > tree;
        int entry_point;
        size_t length;
    };
}

#undef BOUNDARY_OVERFLOW
#endif

#ifndef BIND_TRANSPORT_MPI_CHANNEL
#define BIND_TRANSPORT_MPI_CHANNEL

namespace bind { namespace transport { namespace mpi {

    class request_impl;
    template<class T> class collective;

    static void recv_impl(request_impl* r);
    static void send_impl(request_impl* r);
    static bool test_impl(request_impl* r);

    class channel {
    public:
        typedef typename model::revision block_type;
        typedef typename model::any scalar_type;
        template<class T> using collective_type = collective<T>;
        struct mount {
            mount(); 
           ~mount();
            std::vector<binary_tree<rank_t>*> trees;
            std::vector<rank_t> circle;
            int tag_ub;
            int sid;
            int self;
            int np;
        };
        static mount& setup(){ 
            static mount m; 
            return m; 
        }
        channel();
        size_t dim() const;
        static void barrier();
        collective<block_type>* get(block_type& r);
        collective<block_type>* set(block_type& r);
        collective<scalar_type>* bcast(scalar_type& v, rank_t root);
        collective<scalar_type>* bcast(scalar_type& v);
        rank_t rank;
        group* world;
    };

} } }

#endif

#ifndef BIND_TRANSPORT_MPI_REQUEST
#define BIND_TRANSPORT_MPI_REQUEST

namespace bind { namespace transport { namespace mpi {

    class request_impl : public memory::cpu::use_bulk_new<request_impl> {
    public:
        request_impl(void(*impl)(request_impl*), typename channel::scalar_type& v, rank_t target, int tag = 0);
        request_impl(void(*impl)(request_impl*), typename channel::block_type& r, rank_t target, int tag = 0);
        inline bool operator()();
        void* data;
        int extent;
        int target; // MPI_INT
        MPI_Request mpi_request;
        void(*impl)(request_impl*);
        bool once;
        int tag;
    };

    class request {
        typedef memory::cpu::instr_bulk::allocator<request_impl*> allocator_type;
    public:
        bool operator()();
        void operator &= (request_impl* r);
        void operator += (request_impl* r);
    private:
        std::vector<request_impl*,allocator_type> primaries;
        std::vector<request_impl*,allocator_type> callbacks;
    };

} } }

#endif

#ifndef BIND_TRANSPORT_MPI_COLLECTIVE
#define BIND_TRANSPORT_MPI_COLLECTIVE

namespace bind { namespace transport { namespace mpi {

    template<typename T>
    class bcast {
        typedef memory::cpu::instr_bulk::allocator<int> allocator_type;
    public:
        void dispatch();
        bcast(T& o, rank_t root) : object(o), root(root), self(0) {}
    private:
        template<class C> friend class collective;
        T& object;
        std::vector<int,allocator_type> tags;
        rank_t root;
        int self;
        int size;
        rank_t* list;
        request impl; 
        guard_once once;
    };

    template<class T> class collective {};

    template<>
    class collective<typename channel::block_type> : public bcast<typename channel::block_type>, 
                                                     public memory::cpu::use_bulk_new<collective<typename channel::block_type> > {
        typedef memory::cpu::instr_bulk::allocator<int> allocator_type;
    public:
        collective(typename channel::block_type& r, rank_t root);
        void append(rank_t rank);
        bool involved();
        bool test();
    private:
        std::vector<bool,allocator_type> states;
        std::vector<rank_t,allocator_type> tree;
    };

    template<>
    class collective<typename channel::scalar_type> : public bcast<typename channel::scalar_type>, 
                                                      public memory::cpu::use_bulk_new<collective<typename channel::scalar_type> > {
    public:
        collective(typename channel::scalar_type& v, rank_t root);
        bool test();
    };

} } }

#endif

namespace bind { namespace transport { namespace mpi {

    // type information required //
    inline request_impl::request_impl(void(*impl)(request_impl*), typename channel::scalar_type& v, rank_t target, int tag)
    : extent(v.size/sizeof(double)), 
      data(&v.value),
      target(target),
      impl(impl),
      tag(tag),
      once(false)
    {
    }
    // type information required //
    inline request_impl::request_impl(void(*impl)(request_impl*), typename channel::block_type& r, rank_t target, int tag)
    : extent(r.spec.extent/sizeof(double)), 
      data(r.data),
      target(target),
      impl(impl),
      tag(tag),
      once(false)
    {
    }
    inline bool request_impl::operator()(){
        if(!once){ impl(this); once = true; }
        return test_impl(this);
    }

    inline bool request::operator()(){
        int length = primaries.size();
        for(int i = 0; i < length; i++){
            if(!(*primaries[i])()) return false;
        }
        primaries.clear();
        length = callbacks.size();
        for(int i = 0; i < length; i++){
            if(!(*callbacks[i])()) return false;
        }
        return true;
    }
    inline void request::operator &= (request_impl* r){
        primaries.push_back(r);
    }
    inline void request::operator += (request_impl* r){
        callbacks.push_back(r);
    }

} } }


namespace bind { namespace transport { namespace mpi {

    inline void recv_impl(request_impl* r){
        MPI_Irecv(r->data, r->extent, MPI_DOUBLE, r->target, r->tag, MPI_COMM_WORLD, &r->mpi_request);
    }
    inline void send_impl(request_impl* r){
        MPI_Isend(r->data, r->extent, MPI_DOUBLE, r->target, r->tag, MPI_COMM_WORLD, &r->mpi_request);
    }
    inline bool test_impl(request_impl* r){
        int f = 0; MPI_Test(&r->mpi_request, &f, MPI_STATUS_IGNORE); return f;
    }

    inline channel::mount::mount(){
        int *ub, flag, level, zero = 0;
        MPI_Init_thread(&zero, NULL, BIND_MPI, &level); 
        if(level != BIND_MPI) throw std::runtime_error("Error: Wrong threading level");
        MPI_Comm_size(MPI_COMM_WORLD, &np);
        MPI_Comm_rank(MPI_COMM_WORLD, &self);
        MPI_Attr_get(MPI_COMM_WORLD, MPI_TAG_UB, &ub, &flag);
        this->tag_ub = flag ? *ub : 32767;
        this->sid = 1;
        
        trees.resize(2); // 0,1 are empty
        for(int i = 2; i <= np; i++)  trees.push_back(new binary_tree<rank_t>(i));
        for(int i = 0; i < 2*np; i++) circle.push_back(i % np);
    }

    inline channel::mount::~mount(){
        MPI_Finalize();
    }

    inline channel::channel(){
        channel::setup(); // making sure MPI is initialised
        this->world = new group(MPI_COMM_WORLD);
        this->rank = this->world->rank;
    }

    inline void channel::barrier(){
        MPI_Barrier(MPI_COMM_WORLD);
    }

    inline size_t channel::dim() const {
        return this->world->size;
    }

    inline collective<typename channel::scalar_type>* channel::bcast(scalar_type& v, rank_t root){
        return new collective<scalar_type>(v, root);
    }

    inline collective<typename channel::scalar_type>* channel::bcast(scalar_type& v){
        return new collective<scalar_type>(v, rank);
    }

    inline collective<typename channel::block_type>* channel::get(block_type& r){
        return new collective<block_type>(r, r.owner);
    }

    inline collective<typename channel::block_type>* channel::set(block_type& r){
        return new collective<block_type>(r, rank);
    }

} } }

#define BOUNDARY_OVERFLOW -1

namespace bind { namespace transport { namespace mpi {

    namespace detail {
        inline int self(){
            return channel::setup().self;
        }
        inline int num_procs(){
            return channel::setup().np;
        }
        inline int generate_sid(){
            return (++channel::setup().sid %= channel::setup().tag_ub);
        }
    }

    template<typename T>
    inline void bcast<T>::dispatch(){
        std::pair<rank_t,rank_t> lr = (*channel::setup().trees[size])[self];
        if(!self){ // self == root
            if(lr.first  != BOUNDARY_OVERFLOW) impl &= new request_impl(send_impl, object, list[lr.first],  tags[lr.first]);
            if(lr.second != BOUNDARY_OVERFLOW) impl &= new request_impl(send_impl, object, list[lr.second], tags[lr.second]);
        }else{
            impl &= new request_impl(recv_impl, object, MPI_ANY_SOURCE, tags[self]);
            if(lr.first  != BOUNDARY_OVERFLOW) impl += new request_impl(send_impl, object, list[lr.first],  tags[lr.first]);
            if(lr.second != BOUNDARY_OVERFLOW) impl += new request_impl(send_impl, object, list[lr.second], tags[lr.second]);
        }
    }

    inline collective<typename channel::block_type>::collective(typename channel::block_type& r, rank_t root) 
    : bcast<typename channel::block_type>(r, root), states(detail::num_procs()+1) {
        this->tree.push_back(root);
        this->tags.push_back(-1);
    }

    inline void collective<typename channel::block_type>::append(rank_t rank){
        if(!states[rank]){
            states[rank] = true;
            if(states.back()){
                for(int i = this->tags.size(); i <= detail::num_procs(); i++)
                    this->tags.push_back(detail::generate_sid());
                for(int i = 0; i < detail::num_procs(); i++)
                    this->states[i] = true;
            }else{
                if(rank == detail::self()) this->self = tree.size();
                this->tags.push_back(channel::setup().sid);
                this->tree.push_back(rank);
            }
        }
        detail::generate_sid();
    }

    inline bool collective<typename channel::block_type>::involved(){
        return states[detail::self()] || states.back();
    }

    inline bool collective<typename channel::block_type>::test(){
        if(this->once()){
            if(states.back()){
                this->size = detail::num_procs();
                this->list = &channel::setup().circle[root];
                this->self = (size + detail::self() - root) % size;
            }else{
                this->size = tree.size();
                this->list = &tree[0];
            }
            this->dispatch();
        }
        return this->impl();
    }

    inline collective<typename channel::scalar_type>::collective(typename channel::scalar_type& v, rank_t root)
    : bcast<typename channel::scalar_type>(v, root) {
        tags.reserve(detail::num_procs()+1);
        for(int i = 0; i <= detail::num_procs(); i++)
            this->tags.push_back(detail::generate_sid());
    }

    inline bool collective<typename channel::scalar_type>::test(){
        if(this->once()){
            this->size = detail::num_procs();
            this->list = &channel::setup().circle[root];
            this->self = (size + detail::self() - root) % size;
            this->dispatch();
        }
        return this->impl();
    }

} } }
#else

#ifndef BIND_TRANSPORT_NOP
#define BIND_TRANSPORT_NOP

#define BIND_CHANNEL_NAME nop

namespace bind { namespace transport { namespace nop {

    template<class T> struct collective {
        bool test(){ return true; }
        void append(rank_t rank){}
        bool involved(){ return true; }
    };

    class channel {
    public:
        typedef typename model::revision block_type;
        typedef typename model::any scalar_type;
        template<class T> using collective_type = collective<T>;
        size_t dim() const { return 1; }
        static void barrier(){}
        collective<block_type>* get(block_type& r){ return NULL; }
        collective<block_type>* set(block_type& r){ return NULL; }
        collective<scalar_type>* bcast(scalar_type& v, rank_t root){ return NULL; }
        collective<scalar_type>* bcast(scalar_type& v){ return NULL; }
        static constexpr rank_t rank = 0;
    };

} } }

#endif
#endif
// }}}
// {{{ core package (requires :model :transport)

#ifndef BIND_CORE_COLLECTOR
#define BIND_CORE_COLLECTOR

namespace bind{ namespace memory {

    using model::history;
    using model::revision;
    using model::any;

    class collector {
    public:
        struct delete_ptr {
            void operator()( history* element ) const;
            void operator()( revision* element ) const;
            void operator()( any* element ) const;
        };

        void reserve(size_t n);
        void push_back(history* o);
        void push_back(revision* o);
        void push_back(any* o);
        void clear();
    private:
        size_t reserve_limit;
        std::vector< history* >  str;
        std::vector< revision* > rev;
        std::vector< any* >      raw;
    };

} }

#endif


namespace bind { namespace memory {

    using model::history;
    using model::revision;
    using model::any;

    inline void collector::reserve(size_t n){
        this->rev.reserve(n);
        this->str.reserve(n);
    }

    inline void collector::push_back(any* o){
        this->raw.push_back(o);
    }

    inline void collector::push_back(revision* r){
        if(!r->valid() && r->state != locality::remote){
            assert(r->spec.signature != cpu::bulk::signature);
            assert(r->spec.signature != delegated::signature);
            r->spec.weaken();
        }
        r->spec.crefs--;
        if(!r->referenced()){ // squeeze
            if(r->valid() && !r->locked() && r->spec.signature == cpu::standard::signature){
                r->spec.free(r->data); // artifacts or last one
                r->spec.signature = delegated::signature;
            }
            this->rev.push_back(r);
        }
    }

    inline void collector::push_back(history* o){
        this->push_back(o->current);
        this->str.push_back(o);
    }

    inline void collector::delete_ptr::operator()( revision* r ) const {
        if(r->valid() && r->spec.signature == cpu::standard::signature){
            r->spec.free(r->data); // artifacts
            r->spec.signature = delegated::signature;
        }
        delete r; 
    }

    inline void collector::delete_ptr::operator()( history* e ) const {
        delete e;
    }

    inline void collector::delete_ptr::operator()( any* e ) const {
        memory::cpu::fixed::free(e);
    } 

    inline void collector::clear(){
        std::for_each( rev.begin(), rev.end(), delete_ptr());
        std::for_each( str.begin(), str.end(), delete_ptr());
        std::for_each( raw.begin(), raw.end(), delete_ptr());
        rev.clear();
        str.clear();
        raw.clear();
    }

} }

#ifndef BIND_CORE_NODE
#define BIND_CORE_NODE

namespace bind {

    namespace core {
        class controller;
    }

    class node {
    protected:
        typedef core::controller controller_type;
        node(){}
    public:
       ~node();
        node(std::vector<rank_t>::const_iterator it);
        bool remote() const;
        bool local()  const;
        bool common() const;
        rank_t which()  const;
        friend class core::controller;
    protected:
        rank_t rank;
        locality state;
        controller_type* controller;
    };

    struct node_each : public node {
        node_each(typename node::controller_type* c);
    };

}

#endif

#ifndef BIND_CORE_CONTROLLER
#define BIND_CORE_CONTROLLER

namespace bind { namespace core {

    using model::history;
    using model::revision;
    using model::any;
    using model::functor;

    class controller {
        controller(const controller&) = delete;
        controller& operator=(const controller&) = delete;
        controller(); 
    public:
        typedef transport::BIND_CHANNEL_NAME::channel channel_type;
       ~controller();
        void flush();
        void clear();
        bool queue (functor* f);
        bool update(revision& r);
        void sync  (revision* r);
        void lsync (revision* r);
        void rsync (revision* r);
        void lsync (any* v);
        void rsync (any* v);
        template<typename T> void collect(T* o);
        void squeeze(revision* r) const;

        void touch(const history* o, rank_t owner);
        void use_revision(history* o);
        template<locality L>
        void add_revision(history* o, functor* g, rank_t owner);

        bool verbose() const;
        bool is_serial() const;
        rank_t get_rank() const;
        rank_t get_shared_rank() const;
        int get_num_procs() const;
        channel_type& get_channel();

        void sync();

        controller* activate(node* a);
        void deactivate(node* a);
        node& get_node();
    private:
        size_t clock;
        channel_type channel;
        std::vector< functor* > stack_m;
        std::vector< functor* > stack_s;
        std::vector< functor* >* chains;
        std::vector< functor* >* mirror;
        memory::collector garbage;
        utils::funneled_io io_guard;
        node_each* each;
        node* which;
    public:
        std::vector<rank_t> nodes;
        template<class T>
        struct weak_instance {
            static controller w;
        };
    };
    
} }

namespace bind {
    template<class T> core::controller core::controller::weak_instance<T>::w;
    inline core::controller& select(){ return core::controller::weak_instance<void>::w; }
}

#endif

#ifndef BIND_CORE_GET
#define BIND_CORE_GET

namespace bind { namespace core {
    
    template<class T> class get {};

    template<>
    class get<any> : public functor, public memory::cpu::use_bulk_new<get<any> > {
    public:
        template<class T> using collective = controller::channel_type::collective_type<T>;
        static void spawn(any& v);
        get(any& v);
        virtual void invoke() override;
        virtual bool ready() override;
    private:
        collective<any>* handle;
        any& t;
    };

    template<>
    class get<revision> : public functor, public memory::cpu::use_bulk_new<get<revision> >  {
    public:
        template<class T> using collective = controller::channel_type::collective_type<T>;
        static void spawn(revision& r);
        get(revision& r);
        virtual void invoke() override;
        virtual bool ready() override;
    private:
        void operator += (rank_t rank);
    private:
        collective<revision>* handle;
        revision& t;
    };

} }

#endif


#ifndef BIND_CORE_SET
#define BIND_CORE_SET

namespace bind { namespace core {

    template<class T> class set {};

    template<>
    class set<any> : public functor, public memory::cpu::use_bulk_new<set<any> > {
    public:
        template<class T> using collective = controller::channel_type::collective_type<T>;
        static void spawn(any& v);
        set(any& v);
        virtual void invoke() override;
        virtual bool ready() override;
    private:
        collective<any>* handle;
        any& t;
    };

    template<>
    class set<revision> : public functor, public memory::cpu::use_bulk_new<set<revision> > {
    public:
        template<class T> using collective = controller::channel_type::collective_type<T>;
        static void spawn(revision& r);
        set(revision& r);
        virtual void invoke() override;
        virtual bool ready() override;
    private:
        void operator += (rank_t rank);
    private:
        collective<revision>* handle;
        revision& t;
    };

} }

#endif

namespace bind { namespace nodes {
    inline size_t size(){
        return select().nodes.size();
    }
    inline std::vector<rank_t>::const_iterator begin(){
        return select().nodes.begin();
    }
    inline std::vector<rank_t>::const_iterator end(){
        return select().nodes.end();
    }
    inline rank_t which(){
        return select().get_node().which();
    }
    template<typename V>
    inline rank_t which(const V& o){
        return o.bind_allocator.desc->current->owner;
    }
} }

namespace bind { namespace core {

    inline controller::~controller(){ 
        if(!chains->empty()) printf("Bind:: exiting with operations still in queue!\n");
        this->clear();
        delete this->each;
    }

    inline controller::controller() : chains(&stack_m), mirror(&stack_s), clock(1) {
        this->each = new node_each(this);
        this->which = NULL;
        for(int i = 0; i < get_num_procs(); i++) nodes.push_back(i);
        if(!verbose()) this->io_guard.enable();
    }

    inline void controller::deactivate(node* a){
        which = NULL;
    }

    inline controller* controller::activate(node* n){
        if(which) return NULL;
        which = n;
        return this;
    }

    inline void controller::sync(){
        this->flush();
        this->clear();
        memory::cpu::instr_bulk::drop();
        memory::cpu::data_bulk::drop();
        memory::cpu::comm_bulk::drop();
    }

    inline node& controller::get_node(){
        return (!which) ? *each : *which;
    }

    inline void controller::flush(){
        while(!chains->empty()){
            for(auto task : *chains){
                if(task->ready()){
                    cilk_spawn task->invoke();
                    for(auto d : task->deps) d->ready();
                    mirror->insert(mirror->end(), task->deps.begin(), task->deps.end());
                }else mirror->push_back(task);
            }
            chains->clear();
            std::swap(chains,mirror);
        }
        cilk_sync;
        clock++;
        channel.barrier();
    }

    inline void controller::clear(){
        this->garbage.clear();
    }

    inline bool controller::queue(functor* f){
        this->chains->push_back(f);
        return true;
    }

    inline bool controller::update(revision& r){
        if(r.assist.first != clock){
            r.assist.first = clock;
            return true;
        }
        return false;
    }

    inline void controller::sync(revision* r){
        if(is_serial()) return;
        if(model::common(r)) return;
        if(model::local(r)) set<revision>::spawn(*r);
        else get<revision>::spawn(*r);
    }

    inline void controller::lsync(revision* r){
        if(model::common(r)) return;
        if(!model::local(r)) get<revision>::spawn(*r);
    }

    inline void controller::rsync(revision* r){
        if(model::common(r)) return;
        if(model::local(r)) set<revision>::spawn(*r);
        else get<revision>::spawn(*r); // assist
    }

    inline void controller::lsync(any* v){
        if(is_serial()) return;
        set<any>::spawn(*v);
    }

    inline void controller::rsync(any* v){
        get<any>::spawn(*v);
    }

    template<typename T> void controller::collect(T* o){
        this->garbage.push_back(o);
    }

    inline void controller::squeeze(revision* r) const {
        if(r->valid() && !r->referenced() && r->locked_once()){
            if(r->spec.signature == memory::cpu::standard::signature){
                r->spec.free(r->data);
                r->spec.signature = memory::delegated::signature;
            }
        }
    }

    inline void controller::touch(const history* o, rank_t owner){
        if(o->back() == NULL)
            const_cast<history*>(o)->init_state(owner);
    }

    inline void controller::use_revision(history* o){
        o->back()->use();
    }

    template<locality L>
    void controller::add_revision(history* o, functor* g, rank_t owner){
        o->add_state<L>(g, owner);
    }

    inline rank_t controller::get_rank() const {
        return channel.rank;
    }

    inline rank_t controller::get_shared_rank() const {
        return get_num_procs();
    }

    inline bool controller::is_serial() const {
        return (get_num_procs() == 1);
    }
        
    inline bool controller::verbose() const {
        return (get_rank() == 0);
    }

    inline int controller::get_num_procs() const {
        return channel.dim();
    }

    inline typename controller::channel_type & controller::get_channel(){
        return channel;
    }

} }


namespace bind { namespace core {

    // {{{ any

    inline void get<any>::spawn(any& t){
        bind::select().queue(new get(t));
    }
    inline get<any>::get(any& ptr) : t(ptr) {
        handle = bind::select().get_channel().bcast(t, bind::nodes::which());
        t.generator = this;
    }
    inline bool get<any>::ready(){
        return handle->test();
    }
    inline void get<any>::invoke(){
        t.complete();
    }

    // }}}
    // {{{ revision

    inline void get<revision>::spawn(revision& r){
        get*& transfer = (get*&)r.assist.second;
        if(bind::select().update(r)) transfer = new get(r);
        *transfer += bind::nodes::which();
    }
    inline get<revision>::get(revision& r) : t(r) {
        handle = bind::select().get_channel().get(t);
        t.invalidate();
    }
    inline void get<revision>::operator += (rank_t rank){
        handle->append(rank);
        if(handle->involved() && !t.valid()){
            t.use();
            t.generator = this;
            t.embed(t.spec.hard_malloc<memory::cpu::comm_bulk>()); 
            bind::select().queue(this);
        }
    }
    inline bool get<revision>::ready(){
        return handle->test();
    }
    inline void get<revision>::invoke(){
        bind::select().squeeze(&t);
        t.release();
        t.complete();
    }

    // }}}

} }

namespace bind { namespace core {

    // {{{ any

    inline void set<any>::spawn(any& t){
        t.generator->queue(new set(t));
    }
    inline set<any>::set(any& t) : t(t) {
        handle = bind::select().get_channel().bcast(t, bind::nodes::which());
    }
    inline bool set<any>::ready(){
        return (t.generator != NULL ? false : handle->test());
    }
    inline void set<any>::invoke(){}

    // }}}
    // {{{ revision

    inline void set<revision>::spawn(revision& r){
        set*& transfer = (set*&)r.assist.second;
        if(bind::select().update(r)) transfer = new set(r);
        *transfer += bind::nodes::which();
    }
    inline set<revision>::set(revision& r) : t(r) {
        t.use();
        handle = bind::select().get_channel().set(t);
        if(t.generator != NULL) (t.generator.load())->queue(this);
        else bind::select().queue(this);
    }
    inline void set<revision>::operator += (rank_t rank){
        handle->append(rank);
    }
    inline bool set<revision>::ready(){
        return (t.generator != NULL ? false : handle->test());
    }
    inline void set<revision>::invoke(){
        bind::select().squeeze(&t);
        t.release(); 
    }

    // }}}

} }

#ifndef BIND_CORE_NODE_HPP
#define BIND_CORE_NODE_HPP

namespace bind {

    // {{{ primary node-class

    inline node::~node(){
        if(!controller) return;
        bind::select().deactivate(this);
    }
    inline node::node(std::vector<rank_t>::const_iterator it){
        if(! (controller = bind::select().activate(this)) ) return;
        this->rank = *it;
        this->state = (rank == controller->get_rank()) ? locality::local : locality::remote;
    }
    inline bool node::remote() const {
        return (state == locality::remote);
    }
    inline bool node::local() const {
        return (state == locality::local);
    }
    inline bool node::common() const {
        return (state == locality::common);
    }
    inline rank_t node::which() const {
        return this->rank;
    }

    // }}}
    // {{{ node's special case: everyone does the same

    inline node_each::node_each(typename node::controller_type* c){
        this->controller = c;
        this->rank = controller->get_shared_rank();
        this->state = locality::common;
    }

    // }}}
}

#endif
// }}}
// {{{ interface package (requires :model :transport :core)

#ifndef BIND_INTERFACE_SHORTCUTS
#define BIND_INTERFACE_SHORTCUTS

namespace bind {

    inline void sync(){
        bind::select().sync();
    }

    inline int num_procs(){
        return bind::select().get_num_procs();
    }

    inline int num_threads(){
        static int n = __cilkrts_get_nworkers(); return n;
    }

    inline rank_t rank(){
        return bind::select().get_rank();
    }

    template<typename T>
    inline void destroy(T* o){ 
        bind::select().collect(o); 
    }

    template<typename V>
    inline bool weak(const V& obj){
        return obj.bind_allocator.desc->weak();
    }

    template<typename V>
    inline size_t extent(V& obj){ 
        return obj.bind_allocator.desc->extent;
    }

    template<typename V>
    inline bool locked_once(const V& o){
        return o.bind_allocator.before->locked_once();
    }

}

#endif

#ifndef BIND_INTERFACE_TYPED
#define BIND_INTERFACE_TYPED

#define EXTRACT(var) T* var = (T*)m->arguments[arg];

namespace bind {
    template<typename T> class ptr;
    using model::functor;
    using model::revision;

    // {{{ compile-time type info: singular types + inplace and ptr specializations
    template <typename T> struct singular_info {
        template<size_t arg> static void deallocate     (functor* m){                        }
        template<size_t arg> static bool pin            (functor* m){ return false;          }
        template<size_t arg> static bool ready          (functor* m){ return true;           }
        template<size_t arg> static T&   revised        (functor* m){ EXTRACT(o); return *o; }
        template<size_t arg> static void modify (T& obj, functor* m){
            m->arguments[arg] = (void*)new(memory::cpu::instr_bulk::malloc<sizeof(T)>()) T(obj); 
        }
        template<size_t arg> static void modify_remote(T& obj)      {                        }
        template<size_t arg> static void modify_local(T& obj, functor* m){
            m->arguments[arg] = (void*)new(memory::cpu::instr_bulk::malloc<sizeof(T)>()) T(obj);
        }
        static constexpr bool ReferenceOnly = false;
    };
    template <typename T> struct singular_inplace_info : public singular_info<T> {
        template<size_t arg> static T& revised(functor* m){ return *(T*)&m->arguments[arg]; }
        template<size_t arg> static void modify_remote(T& obj){ }
        template<size_t arg> static void modify_local(T& obj, functor* m){ *(T*)&m->arguments[arg] = obj; }
        template<size_t arg> static void modify(T& obj, functor* m){ *(T*)&m->arguments[arg] = obj; }
    };
    template <typename T> struct ptr_info : public singular_info<T> {
        template<size_t arg> static void deallocate(functor* m){
            EXTRACT(o); o->impl->complete();
        }
        template<size_t arg> static void modify_remote(T& obj){
            obj.resit();
            bind::select().rsync(obj.impl);
        }
        template<size_t arg> static void modify_local(const T& obj, functor* m){
            obj.resit();
            obj.impl->generator = m;
            bind::select().lsync(obj.impl);
            m->arguments[arg] = memory::cpu::instr_bulk::malloc<sizeof(T)>(); memcpy(m->arguments[arg], &obj, sizeof(T)); 
        }
        template<size_t arg> static void modify(const T& obj, functor* m){
            obj.resit();
            obj.impl->generator = m;
            m->arguments[arg] = memory::cpu::instr_bulk::malloc<sizeof(T)>(); memcpy(m->arguments[arg], &obj, sizeof(T)); 
        }
        template<size_t arg> static bool ready(functor* m){
            EXTRACT(o);
            if(o->impl->origin && o->impl->origin->generator != NULL) return false;
            return (o->impl->generator == m || o->impl->generator == NULL);
        }
        template<size_t arg> static T& revised(functor* m){
            EXTRACT(o);
            if(o->impl->origin){
                *o->impl = (typename T::element_type&)*o->impl->origin;
                o->impl->origin = NULL;
            }
            return *o;
        }
        static constexpr bool ReferenceOnly = true;
    };
    template <typename T> struct read_ptr_info : public ptr_info<T> {
        template<size_t arg> static void deallocate(functor* m){ 
        }
        template<size_t arg> static void modify_remote(T& obj){
        }
        template<size_t arg> static void modify_local(const T& obj, functor* m){
            m->arguments[arg] = memory::cpu::instr_bulk::malloc<sizeof(T)>(); memcpy(m->arguments[arg], &obj, sizeof(T)); 
        }
        template<size_t arg> static void modify(const T& obj, functor* m){
            m->arguments[arg] = memory::cpu::instr_bulk::malloc<sizeof(T)>(); memcpy(m->arguments[arg], &obj, sizeof(T)); 
        }
        template<size_t arg> static T& revised(functor* m){
            EXTRACT(o); return *o;
        }
    };
    // }}}
    // {{{ compile-time type info: iteratable derived types
    template <typename T> struct iteratable_info : public singular_info<T> {
        template<size_t arg> 
        static void deallocate(functor* m){
            EXTRACT(o);
            revision& parent  = *o->bind_allocator.before;
            revision& current = *o->bind_allocator.after;
            current.complete();
            current.release();
            bind::select().squeeze(&parent);
            parent.release();
        }
        template<size_t arg>
        static void modify_remote(T& obj){
            auto o = obj.bind_allocator.desc;
            bind::select().touch(o, bind::rank());
            if(o->back()->owner != bind::nodes::which())
                bind::select().rsync(o->back());
            bind::select().collect(o->back());
            bind::select().add_revision<locality::remote>(o, NULL, bind::nodes::which()); 
        }
        template<size_t arg>
        static void modify_local(T& obj, functor* m){
            auto o = obj.bind_allocator.desc;
            bind::select().touch(o, bind::rank());
            T* var = (T*)memory::cpu::instr_bulk::malloc<sizeof(T)>(); memcpy((void*)var, &obj, sizeof(T)); 
            m->arguments[arg] = (void*)var;
            bind::select().lsync(o->back());
            bind::select().use_revision(o);

            var->bind_allocator.before = o->current;
            if(o->current->generator != m){
                bind::select().collect(o->back());
                bind::select().add_revision<locality::local>(o, m, bind::rank());
            }
            bind::select().use_revision(o);
            var->bind_allocator.after = o->current;
        }
        template<size_t arg>
        static void modify(T& obj, functor* m){
            auto o = obj.bind_allocator.desc;
            bind::select().touch(o, bind::rank());
            T* var = (T*)memory::cpu::instr_bulk::malloc<sizeof(T)>(); memcpy((void*)var, &obj, sizeof(T)); m->arguments[arg] = (void*)var;
            bind::select().sync(o->back());
            bind::select().use_revision(o);

            var->bind_allocator.before = o->current;
            if(o->current->generator != m){
                bind::select().collect(o->back());
                bind::select().add_revision<locality::common>(o, m, bind::rank()); 
            }
            bind::select().use_revision(o);
            var->bind_allocator.after = o->current;
        }
        template<size_t arg>
        static T& revised(functor* m){ 
            EXTRACT(o); revise(*o);
            return *o;
        }
        template<size_t arg> 
        static bool pin(functor* m){ 
            EXTRACT(o);
            revision& r = *o->bind_allocator.before;
            if(r.generator != NULL && r.generator != m){
                (r.generator.load())->queue(m);
                return true;
            }
            return false;
        }
        template<size_t arg> 
        static bool ready(functor* m){
            EXTRACT(o);
            revision& r = *o->bind_allocator.before;
            if(r.generator == NULL || r.generator == m) return true;
            return false;
        }
        static constexpr bool ReferenceOnly = true;
    };
    // }}}
    // {{{ compile-time type info: only read/write iteratable derived types

    template <typename T> struct read_iteratable_info : public iteratable_info<T> {
        template<size_t arg> static void deallocate(functor* m){
            EXTRACT(o);
            revision& r = *o->bind_allocator.before;
            bind::select().squeeze(&r);
            r.release();
        }
        template<size_t arg> static void modify_remote(T& obj){
            auto o = obj.bind_allocator.desc;
            bind::select().touch(o, bind::rank());
            if(o->back()->owner != bind::nodes::which())
                bind::select().rsync(o->back());
        }
        template<size_t arg> static void modify_local(T& obj, functor* m){
            auto o = obj.bind_allocator.desc;
            bind::select().touch(o, bind::rank());
            T* var = (T*)memory::cpu::instr_bulk::malloc<sizeof(T)>(); memcpy((void*)var, &obj, sizeof(T)); m->arguments[arg] = (void*)var;
            var->bind_allocator.before = var->bind_allocator.after = o->current;
            bind::select().lsync(o->back());
            bind::select().use_revision(o);
        }
        template<size_t arg> static void modify(T& obj, functor* m){
            auto o = obj.bind_allocator.desc;
            bind::select().touch(o, bind::rank());
            T* var = (T*)memory::cpu::instr_bulk::malloc<sizeof(T)>(); memcpy((void*)var, &obj, sizeof(T)); m->arguments[arg] = (void*)var;
            var->bind_allocator.before = var->bind_allocator.after = o->current;
            bind::select().sync(o->back());
            bind::select().use_revision(o);
        }
        template<size_t arg> 
        static bool pin(functor* m){ 
            EXTRACT(o);
            revision& r = *o->bind_allocator.before;
            if(r.generator != NULL){
                (r.generator.load())->queue(m);
                return true;
            }
            return false;
        }
    };
    template <typename T> struct write_iteratable_info : public iteratable_info<T> {
        template<size_t arg> static void modify_remote(T& obj){
            auto o = obj.bind_allocator.desc;
            bind::select().touch(o, bind::rank());
            bind::select().collect(o->back());
            bind::select().add_revision<locality::remote>(o, NULL, bind::nodes::which()); 
        }
        template<size_t arg> static void modify_local(T& obj, functor* m){
            auto o = obj.bind_allocator.desc;
            bind::select().touch(o, bind::rank());
            T* var = (T*)memory::cpu::instr_bulk::malloc<sizeof(T)>(); memcpy((void*)var, (void*)&obj, sizeof(T)); m->arguments[arg] = (void*)var;

            bind::select().use_revision(o);
            bind::select().collect(o->back());

            var->bind_allocator.before = o->current;
            bind::select().add_revision<locality::local>(o, m, bind::rank()); 
            bind::select().use_revision(o);
            var->bind_allocator.after = o->current;
        }
        template<size_t arg> static void modify(T& obj, functor* m){
            auto o = obj.bind_allocator.desc;
            bind::select().touch(o, bind::rank());
            T* var = (T*)memory::cpu::instr_bulk::malloc<sizeof(T)>(); memcpy((void*)var, (void*)&obj, sizeof(T)); m->arguments[arg] = (void*)var;
            bind::select().use_revision(o);
            bind::select().collect(o->back());

            var->bind_allocator.before = o->current;
            bind::select().add_revision<locality::common>(o, m, bind::rank()); 
            bind::select().use_revision(o);
            var->bind_allocator.after = o->current;
        }
        template<size_t arg> static bool pin(functor* m){ return false; }
        template<size_t arg> static bool ready (functor* m){ return true;  }
    };
    // }}}

    // {{{ compile-time type info: specialization for forwarded types

    template <typename T>
    struct is_polymorphic {
        template <typename T1> static typename T1::async_type test(int);
        template <typename>    static void test(...);
        enum { value = !std::is_void<decltype(test<T>(0))>::value };
    };
    template <bool HAS, typename T> struct checked_get_async_type { typedef int type; };
    template <typename T> struct checked_get_async_type<true, T>  { typedef typename T::async_type type; };
    template <typename T> struct get_async_type { typedef typename checked_get_async_type<is_polymorphic<T>::value, T>::type type; };

    template <typename T> struct has_versioning {
        template <typename T1> static typename T1::bind_type_structure test(int);
        template <typename>    static void test(...);
        enum { value = !std::is_void<decltype(test<T>(0))>::value };
    };

    template <bool V, typename T> struct versioned_info { };
    template<typename T> struct versioned_info<true, T> { typedef iteratable_info< T > type; };
    template<typename T> struct versioned_info<false, T> { typedef singular_info< T > type; };

    template <bool V, typename T> struct const_versioned_info { };
    template<typename T> struct const_versioned_info<true, T> { typedef read_iteratable_info< const T > type; };
    template<typename T> struct const_versioned_info<false, T> { typedef singular_info< const T > type; };

    template <typename T>
    struct info {
        typedef typename versioned_info<has_versioning<T>::value,T>::type typed;
    };
    template <typename T>
    struct info <const T> {
        typedef typename const_versioned_info<has_versioning<T>::value,T>::type typed;
    };

    template <typename T>
    struct info <volatile T> {
        typedef write_iteratable_info<volatile T> typed;
    };

    template <typename S>
    struct info < ptr<S> > {
        typedef ptr_info<ptr<S> > typed; 
    };

    template <typename S>
    struct info < const ptr<S> > { 
        typedef read_ptr_info<const ptr<S> > typed; 
    };

    template <>
    struct info < size_t > {
        typedef singular_inplace_info<size_t> typed; 
    };

    // }}}

    #define BIND_DELEGATE(...)       struct  bind_type_structure { __VA_ARGS__ }; \
                                     mutable allocator_type bind_allocator;

    #define BIND_VAR_LENGTH 1
}

#undef EXTRACT
#endif

#ifndef BIND_INTERFACE_ALLOCATOR
#define BIND_INTERFACE_ALLOCATOR

namespace bind {
    using model::history;
    using model::revision;

    struct stateful {
        revision* before;
        revision* after;
    };

    struct allocator : public stateful {
        allocator& operator=(const allocator&) = delete;
        allocator(){ }
        allocator(size_t size){
            desc = new history(size);
        }
        allocator(const allocator& origin){
            desc = new history(origin.desc->extent);
            revision* r = origin.desc->back(); if(!r) return;
            desc->current = r;
            if(!r->valid() && r->state != locality::remote)
                r->spec.protect(); // keep origin intact
            r->spec.crefs++;
        }
       ~allocator(){
            if(desc->weak()) delete desc;
            else destroy(desc);
        }
        static void* alloc(memory::descriptor& spec){
            return spec.malloc();
        }
        static void* calloc(memory::descriptor& spec){
            void* m = alloc(spec); memset(m, 0, spec.extent); return m;
        }
        static void free(void* ptr, memory::descriptor& spec){
            spec.free(ptr);
        }
        history* desc;
    };
}

#endif

#ifndef BIND_INTERFACE_KERNEL_INLINER
#define BIND_INTERFACE_KERNEL_INLINER

namespace bind {

    template <typename T>
    using remove_reference = typename std::remove_reference<T>::type;
    using model::functor;

    template<typename T>
    struct check_if_not_reference {
        template<bool C, typename F>  struct fail_if_true { typedef F type; };
        template<typename F> struct fail_if_true<true, F> { };
        typedef typename fail_if_true<info<T>::typed::ReferenceOnly, T>::type type; // T can be passed only by reference
    };
 
    template<typename T>
    struct check_if_not_reference<T&> {
        typedef T type;
    };

    template<int N> void expand_modify_remote(){}
    template<int N> void expand_modify_local(functor* o){}
    template<int N> void expand_modify(functor* o){}
    template<int N> bool expand_pin(functor* o){ return false; }
    template<int N> void expand_deallocate(functor* o){ }
    template<int N> bool expand_ready(functor* o){ return true; }

    template<int N, typename T, typename... TF>
    void expand_modify_remote(T& arg, TF&... other){
        info<T>::typed::template modify_remote<N>(arg);
        expand_modify_remote<N+1>(other...);
    }
    template<int N, typename T, typename... TF>
    void expand_modify_local(functor* o, T& arg, TF&... other){
        info<T>::typed::template modify_local<N>(arg, o);
        expand_modify_local<N+1>(o, other...);
    }
    template<int N, typename T, typename... TF>
    void expand_modify(functor* o, T& arg, TF&... other){
        info<T>::typed::template modify<N>(arg, o);
        expand_modify<N+1>(o, other...);
    }
    template<int N, typename T, typename... TF>
    bool expand_pin(functor* o){
        return info<remove_reference<T> >::typed::template pin<N>(o) ||
               expand_pin<N+1,TF...>(o);
    }
    template<int N, typename T, typename... TF>
    void expand_deallocate(functor* o){
        info<remove_reference<T> >::typed::template deallocate<N>(o);
        expand_deallocate<N+1,TF...>(o);
    }
    template<int N, typename T, typename... TF>
    bool expand_ready(functor* o){
        return info<remove_reference<T> >::typed::template ready<N>(o) &&
               expand_ready<N+1,TF...>(o);
    }

    template<typename FP, FP fp>
    struct kernel_inliner {};

    template< typename... TF , void(*fp)( TF... )>
    struct kernel_inliner<void(*)( TF... ), fp> {
        template <int N>
        using get_type = remove_reference< typename check_if_not_reference< 
                             typename std::tuple_element<N, std::tuple<TF...> >::type 
                         >::type >;
        static const int arity = sizeof...(TF);

        static inline void latch(functor* o, TF&... args){
            if(bind::select().get_node().remote())   { expand_modify_remote<0>(args...); return; }
            else if(bind::select().get_node().local()) expand_modify_local<0>(o, args...);
            else                                       expand_modify<0>(o, args...);
            expand_pin<0,TF...>(o) || bind::select().queue(o);
        }
        static inline void cleanup(functor* o){
            expand_deallocate<0,TF...>(o);
        }
        static inline bool ready(functor* o){
            return expand_ready<0,TF...>(o);
        }
        template<size_t...I>
        static void expand_invoke(std::index_sequence<I...>, functor* o){
            (*fp)(info<remove_reference<TF> >::typed::template revised<I>(o)...);
        }
        static inline void invoke(functor* o){
            expand_invoke(std::make_index_sequence<sizeof...(TF)>(), o);
        }
    };

}

#endif


#ifndef BIND_INTERFACE_KERNEL
#define BIND_INTERFACE_KERNEL

namespace bind {

    using model::functor;

    template<class K>
    class kernel : public functor {
    public:
        #define inliner kernel_inliner<typename K::ftype,K::c>
        inline void operator delete (void* ptr){ }
        inline void* operator new (size_t size){
            return memory::cpu::instr_bulk::malloc<sizeof(K)+sizeof(void*)*inliner::arity>();
        }
        virtual bool ready() override { 
            return inliner::ready(this);
        }
        virtual void invoke() override {
            inliner::invoke(this);
            inliner::cleanup(this);
        }
        template<size_t...I, typename... Args>
        static void expand_spawn(std::index_sequence<I...>, Args&... args){
            inliner::latch(new kernel(), args...);
        }
        template<typename... Args>
        static inline void spawn(Args&... args){
            expand_spawn(std::make_index_sequence<sizeof...(Args)>(), args...);
        }
        #undef inliner
    };
}

#endif

#ifndef BIND_INTERFACE_ACCESS
#define BIND_INTERFACE_ACCESS

namespace bind {

    using model::revision;

    namespace ext {

        template<typename V>
        void swap(V& left, V& right){
            // swapping allocators should be better
            std::swap(left.bind_allocator.desc, right.bind_allocator.desc);
            left.bind_allocator.after = left.bind_allocator.desc->current;
            right.bind_allocator.after = right.bind_allocator.desc->current;
        }

        template <typename T> static void transform(const T& obj){
            if(!is_polymorphic<T>::value) return;
            new ((void*)&obj) typename get_async_type<T>::type();
        }
    }

    template <typename T> static T& load(T& obj){ 
        bind::select().touch(obj.bind_allocator.desc, bind::rank());
        bind::sync(); 
        revision& c = *obj.bind_allocator.desc->current;
        assert(c.state == locality::local || c.state == locality::common);
        if(!c.valid()) c.embed(obj.bind_allocator.calloc(c.spec));
        obj.bind_allocator.after = obj.bind_allocator.desc->current;
        return obj;
    }

    template <typename T> static auto delegated(T& obj) -> typename T::bind_type_structure& {
        return *(typename T::bind_type_structure*)(*obj.bind_allocator.after);
    }

    template <typename T> static void revise(const T& obj){
        ext::transform(obj);
        revision& c = *obj.bind_allocator.before; if(c.valid()) return;
        c.embed(obj.bind_allocator.calloc(c.spec));
    }

    template <typename T> static void revise(volatile T& obj){
        ext::transform(obj);
        revision& c = *obj.bind_allocator.after; if(c.valid()) return;
        revision& p = *obj.bind_allocator.before;
        if(p.valid() && p.locked_once() && !p.referenced() && c.spec.conserves(p.spec)) c.reuse(p);
        else c.embed(obj.bind_allocator.alloc(c.spec));
    }

    template <typename T> static void revise(T& obj){
        ext::transform(obj);
        revision& c = *obj.bind_allocator.after; if(c.valid()) return;
        revision& p = *obj.bind_allocator.before;
        if(!p.valid()) c.embed(obj.bind_allocator.calloc(c.spec));
        else if(p.locked_once() && !p.referenced() && c.spec.conserves(p.spec)) c.reuse(p);
        else{
            c.embed(obj.bind_allocator.alloc(c.spec));
            memcpy((T*)c, (T*)p, p.spec.extent);
        }
    }
}

#endif

#ifndef BIND_INTERFACE_LAMBDA
#define BIND_INTERFACE_LAMBDA

namespace bind {

    template<typename F, typename... T>
    struct lambda_kernel : public kernel< lambda_kernel<F, T...> > {
        typedef void(*ftype)(T..., F&);
        static void fw(T... args, F& func){ func(args...); }
        static constexpr ftype c = &fw;
    };

    template <typename Function>
    struct function_traits : public function_traits<decltype(&Function::operator())> {};

    template <typename ClassType, typename ReturnType, typename... Args>
    struct function_traits<ReturnType(ClassType::*)(Args...) const> {
        typedef ReturnType (*pointer)(Args...);
        typedef const std::function<ReturnType(Args...)> function;
        typedef lambda_kernel<const std::function<ReturnType(Args...)>, Args... > kernel_type;
    };

    template <typename Function>
    typename function_traits<Function>::function to_function (Function& lambda) {
        return static_cast<typename function_traits<Function>::function>(lambda);
    }

    template <class L>
    struct overload_lambda : L {
        overload_lambda(L l) : L(l) {}
        template <typename... T>
        void operator()(T&& ... values){
            function_traits<L>::kernel_type::spawn(std::forward<T>(values)... , to_function(*(L*)this));
        }
    };

    template <class L>
    overload_lambda<L> lambda(L l){
        return overload_lambda<L>(l);
    }

    template <class L, class... Args>
    void cpu(L l, Args&& ... args){
        lambda(l)(std::forward<Args>(args)...);
    }

    template <class... L, class... Args>
    void cpu(void(*l)(L...), Args&& ... args){
        bind::cpu(std::function<void(L...)>(l), std::forward<Args>(args)...);
    }

}

#endif

// }}}
// {{{ bonus container package (requires :*)

#ifndef BIND_CONTAINER_PTR_HPP
#define BIND_CONTAINER_PTR_HPP

namespace bind {

    using model::any;
    using model::sizeof_any;

    template <typename T>
    class ptr {
    private:
        template <typename F> friend class ptr;
        template<typename S> 
        ptr& operator= (const S& val) = delete;
    public:
        mutable any* impl;
        typedef T element_type;

        void resit() const {
            ptr clone(*this);
            std::swap(this->impl, clone.impl);
            this->impl->origin = clone.impl;
        }
       ~ptr(){
           if(impl) bind::destroy(impl); 
        }
        T& operator* () const {
            return *impl;
        }
        ptr(element_type val){
            impl = new (memory::cpu::fixed::calloc<sizeof_any<T>()>()) any(val);
        }
        ptr(const ptr& f){
            impl = new (memory::cpu::fixed::calloc<sizeof_any<T>()>()) any((element_type&)*f);
            impl->origin = f.impl;
        }
        ptr& operator= (const ptr& f){
            *impl = (element_type&)*f;
            impl->origin = f.impl;
            return *this;
        }
        ptr(ptr&& f){
            impl = f.impl; f.impl = NULL; 
        }
        ptr& operator= (ptr&& f){ 
            std::swap(impl, f.impl);
            return *this;
        }
    };

    template<class T>
    std::ostream& operator << (std::ostream& os, const ptr<T>& obj){
        os << *obj;
        return os;
    }
}

#endif

#ifndef BIND_CONTAINER_BLOCK
#define BIND_CONTAINER_BLOCK

namespace bind {
     
    template<typename T, class Allocator = bind::allocator> class block;
    namespace detail { 
        template<typename T>
        void fill_value(volatile block<T>& a, T& value){
            block<T>& a_ = const_cast<block<T>&>(a);
            size_t size = a_.num_rows()*a_.num_cols();
            T* ad = a_.data();
            for(size_t i = 0; i < size; ++i) ad[i] = value;
        }
    }

    template <class T, class Allocator>
    class block {
    public:
        typedef Allocator allocator_type;
        typedef T value_type;
        block(size_t m, size_t n) : bind_allocator(sizeof(T)*m*n), rows(m), cols(n) {}
        void init(T value){
            bind::cpu(detail::fill_value<T>, *this, value);
        }
        value_type& operator()(size_t i, size_t j){
            return data()[ j*rows + i ];
        }
        const value_type& operator()(size_t i, size_t j) const {
            return data()[ j*rows + i ];
        }
        value_type* data() volatile {
            return bind::delegated(*this).data;
        }
        const value_type* data() const volatile {
            return bind::delegated(*this).data;
        }
        size_t num_rows() const {
            return rows;
        }
        size_t num_cols() const {
            return cols;
        }
        size_t rows;
        size_t cols;
    BIND_DELEGATE(
        value_type data[ BIND_VAR_LENGTH ]; 
    )};

}

#endif

#ifndef BIND_CONTAINER_VECTOR_VECTOR_H
#define BIND_CONTAINER_VECTOR_VECTOR_H

namespace bind {

    template<class T, class Allocator>
    class vector_async;

    template <class T, class Allocator = bind::allocator>
    class vector {
    public:
        void* operator new (size_t size, void* ptr){ return ptr; }
        void  operator delete (void*, void*){ /* doesn't throw */ }
        void* operator new (size_t sz){ return memory::cpu::fixed::malloc<sizeof(vector)>(); }
        void operator delete (void* ptr){ memory::cpu::fixed::free(ptr); }
    public:
        typedef vector_async<T,Allocator> async_type;
        typedef Allocator allocator_type;
        typedef T value_type;
        typedef size_t size_type;
        typedef size_t difference_type;
        typedef T* iterator;
        typedef const T* const_iterator;
        explicit vector(){}

        size_t capacity() const;
        size_t cached_size() const;

        /* prohibited in async mode (sync mode only) */

        explicit vector(size_t n, T value = T());
        vector(const vector& a) = default;
        vector& operator = (const vector& rhs);
        template<class OtherAllocator>
        vector& operator = (const vector<T,OtherAllocator>& rhs);

        void init(T value);
        void auto_reserve();

        virtual void reserve(size_t n);
        virtual void shrink_to_fit();
        virtual size_t measure() const; // causes sync, updates cached size
        virtual void load() const;      // causes sync, sets right pointers

        /* using cached size */

        virtual void swap(vector<T,Allocator>& r);
        virtual size_t size() const;
        virtual bool empty() const;
        virtual void resize(size_t sz);
        virtual void clear();

        /* using data-access (load required if not async) */

        value_type* data();
        value_type& operator[](size_t i);
        value_type& at(size_type i);
        value_type& front();
        value_type& back();
        iterator begin();
        iterator end();

        const value_type* data() const;
        const value_type& operator[](size_t i) const;
        const value_type& at(size_type i) const;
        const value_type& front() const;
        const value_type& back() const;
        const_iterator cbegin() const;
        const_iterator cend() const;

        virtual void push_back(value_type value);
        virtual void pop_back();
        virtual iterator insert(const_iterator position, value_type val);
        virtual iterator erase(const_iterator position);
    private:
        mutable size_t cached_size_;
    public:
    BIND_DELEGATE(
        size_t size_;
        value_type data[ BIND_VAR_LENGTH ]; 
    )};

}

namespace std {

    template<typename T>
    class vector<T, bind::allocator> : public bind::vector<T, bind::allocator> {
    public:
        vector(int n){
            printf("my vector!\n");
        }
    };
}

#endif

#ifndef BIND_CONTAINER_VECTOR_VECTOR_HPP
#define BIND_CONTAINER_VECTOR_VECTOR_HPP

namespace bind {
     
    template<class T, class Allocator> class vector;
    namespace detail {
        template<typename T, typename Allocator>
        void set_size(bind::vector<T,Allocator>& a, const size_t& size){
            a.resize(size);
        }
        template<typename T, typename Allocator>
        void measure_size(const bind::vector<T,Allocator>& a, bind::ptr<size_t>& size){
            *size = a.size();
        }
        template<class T, class Allocator>
        void init_value_vector(volatile bind::vector<T,Allocator>& a, T& value){
            bind::vector<T,Allocator>& a_ = const_cast<bind::vector<T,Allocator>&>(a);
            a_.resize(a_.cached_size());
            for(size_t i = 0; i < a_.size(); ++i) a_[i] = value;
        }
        template<class T, class Allocator, class OtherAllocator = Allocator>
        void copy_vector(volatile bind::vector<T,Allocator>& dst, const bind::vector<T,OtherAllocator>& src, const size_t& n){
            bind::vector<T,Allocator>& dst_ = const_cast<bind::vector<T,Allocator>&>(dst);
            for(size_t i = 0; i < n; ++i) dst_[i] = src[i];
        }
        template<typename T, typename Allocator>
        void add(bind::vector<T,Allocator>& a, const bind::vector<T,Allocator>& b){
            for(int i = 0; i < a.size(); ++i) a[i] += b[i];
        }
    }

    template<class T, class Allocator>
    size_t vector<T,Allocator>::capacity() const {
        return (bind::extent(*this)-sizeof(size_t))/sizeof(T);
    }

    template<class T, class Allocator>
    size_t vector<T,Allocator>::cached_size() const {
        return cached_size_;
    }

    /* prohibited in async mode (sync mode only) */

    template<class T, class Allocator>
    vector<T,Allocator>::vector(size_t n, T value) : bind_allocator(n*sizeof(T)+sizeof(size_t)), cached_size_(n) {
        this->init(value);
    }

    template <typename T, class Allocator>
    vector<T,Allocator>& vector<T,Allocator>::operator = (const vector& rhs){
        vector c(rhs);
        this->swap(c);
        return *this;
    }

    template <typename T, class Allocator>
    template <class OtherAllocator>
    vector<T,Allocator>& vector<T,Allocator>::operator = (const vector<T,OtherAllocator>& rhs){
        vector resized(rhs.capacity());
        this->swap(resized);
        this->cached_size_ = rhs.cached_size();

        if(!bind::weak(rhs)) bind::cpu(detail::copy_vector<T,Allocator,OtherAllocator>, *this, rhs, this->cached_size_);
        return *this;
    }

    template<class T, class Allocator>
    void vector<T,Allocator>::init(T value){
        bind::cpu(detail::init_value_vector<T,Allocator>, *this, value);
    }

    template<typename T, class Allocator>
    void vector<T,Allocator>::auto_reserve(){
        if(this->cached_size() == this->capacity()){
            this->reserve(this->cached_size()*2);
        }
    }

    template<class T, class Allocator>
    void vector<T,Allocator>::reserve(size_t n){
        if(capacity() >= n) return;
        size_t current_size = cached_size();
        vector reserved(n);
        if(!bind::weak(*this)) bind::cpu(detail::copy_vector<T,Allocator>, reserved, *this, current_size);
        this->swap(reserved);
        cached_size_ = current_size;
    }

    template<typename T, class Allocator>
    void vector<T,Allocator>::shrink_to_fit(){
        if(memory::aligned_64(cached_size()*sizeof(T)+sizeof(size_t)) ==
           memory::aligned_64(capacity()*sizeof(T)+sizeof(size_t))) return;

        size_t current_size = cached_size();
        vector shrinked(cached_size());
        if(!bind::weak(*this)) bind::cpu(detail::copy_vector<T,Allocator>, shrinked, *this, current_size);
        this->swap(shrinked);
    }

    template<class T, class Allocator>
    size_t vector<T,Allocator>::measure() const {
        bind::ptr<size_t> measured(0);
        bind::cpu(detail::measure_size<T,Allocator>, *this, measured);
        bind::sync();
        cached_size_ = *measured;
        return cached_size();
    }

    template<typename T, class Allocator>
    void vector<T,Allocator>::load() const {
        bind::load(*this);
    }

    /* using cached size */

    template<class T, class Allocator>
    void vector<T,Allocator>::swap(vector<T,Allocator>& r){
        bind::ext::swap(*this, r);
        std::swap(this->cached_size_, r.cached_size_);
    }

    template<class T, class Allocator>
    size_t vector<T,Allocator>::size() const {
        return cached_size();
    }

    template<class T, class Allocator>
    bool vector<T,Allocator>::empty() const {
        return (bind::weak(*this) || (cached_size() == 0));
    }

    template<class T, class Allocator>
    void vector<T,Allocator>::resize(size_t sz){
        reserve(sz);
        cached_size_ = sz;
        bind::cpu(detail::set_size<T,Allocator>, *this, sz);
    }

    template<typename T, class Allocator>
    void vector<T,Allocator>::clear(){
        vector tmp;
        this->swap(tmp);
    }

    /* using data-access methods (load required if not async) */

    template<class T, class Allocator>
    typename vector<T,Allocator>::value_type* vector<T,Allocator>::data(){
        return bind::delegated(*this).data;
    }

    template<class T, class Allocator>
    typename vector<T,Allocator>::value_type& vector<T,Allocator>::operator[](size_t i){
        return bind::delegated(*this).data[ i ];
    }

    template<typename T, class Allocator>
    typename vector<T,Allocator>::value_type& vector<T,Allocator>::at(size_type i){
        if(i >= size()) throw std::out_of_range("vector::out_of_range");
        return (*this)[i];
    }

    template<typename T, class Allocator>
    typename vector<T,Allocator>::value_type& vector<T,Allocator>::front(){
        return (*this)[0];
    }

    template<typename T, class Allocator>
    typename vector<T,Allocator>::value_type& vector<T,Allocator>::back(){
        return (*this)[size()-1];
    }

    template<typename T, class Allocator>
    typename vector<T,Allocator>::iterator vector<T,Allocator>::begin(){
        return this->data();
    }

    template<typename T, class Allocator>
    typename vector<T,Allocator>::iterator vector<T,Allocator>::end(){
        return this->begin()+size();
    }

    template<class T, class Allocator>
    const typename vector<T,Allocator>::value_type* vector<T,Allocator>::data() const {
        return bind::delegated(*this).data;
    }

    template<class T, class Allocator>
    const typename vector<T,Allocator>::value_type& vector<T,Allocator>::operator[](size_t i) const {
        return bind::delegated(*this).data[ i ];
    }

    template<typename T, class Allocator>
    const typename vector<T,Allocator>::value_type& vector<T,Allocator>::at(size_type i) const {
        if(i >= size()) throw std::out_of_range("vector::out_of_range");
        return (*this)[i];
    }

    template<typename T, class Allocator>
    const typename vector<T,Allocator>::value_type& vector<T,Allocator>::front() const {
        return (*this)[0];
    }

    template<typename T, class Allocator>
    const typename vector<T,Allocator>::value_type& vector<T,Allocator>::back() const {
        return (*this)[size()-1];
    }

    template<typename T, class Allocator>
    typename vector<T,Allocator>::const_iterator vector<T,Allocator>::cbegin() const {
        return this->data();
    }

    template<typename T, class Allocator>
    typename vector<T,Allocator>::const_iterator vector<T,Allocator>::cend() const {
        return this->begin()+size();
    }

    template<class T, class Allocator>
    void vector<T,Allocator>::push_back(value_type value){
        auto_reserve();
        bind::sync();
        (*this)[cached_size_] = value;
        bind::delegated(*this).size_ = ++cached_size_;
    }

    template<class T, class Allocator>
    void vector<T,Allocator>::pop_back(){
        bind::delegated(*this).size_ = --cached_size_;
    }

    template<typename T, class Allocator>
    typename vector<T,Allocator>::iterator vector<T,Allocator>::insert(const_iterator position, value_type val){
        auto_reserve();
        bind::sync();
        for(int i = size(); i > (position-this->cbegin()); i--) (*this)[i] = (*this)[i-1];
        (*this)[position-this->cbegin()] = val;
        bind::delegated(*this).size_ = ++cached_size_;
        return (this->begin()+(position-this->cbegin()));
    }

    template<typename T, class Allocator>
    typename vector<T,Allocator>::iterator vector<T,Allocator>::erase(const_iterator position){
        for(int i = (position-this->cbegin()); i < size()-1; i++) (*this)[i] = (*this)[i+1];
        bind::delegated(*this).size_ = --cached_size_;
        return (this->begin()+(position-this->cbegin()));
    }

}

#endif

#ifndef BIND_CONTAINER_VECTOR_VECTOR_ASYNC_H
#define BIND_CONTAINER_VECTOR_VECTOR_ASYNC_H


namespace bind {

    template <class T, class Allocator>
    class vector_async : public vector<T,Allocator> {
    public:
        typedef typename vector<T,Allocator>::allocator_type allocator_type;
        typedef typename vector<T,Allocator>::value_type value_type;
        typedef typename vector<T,Allocator>::size_type size_type;
        typedef typename vector<T,Allocator>::difference_type difference_type;
        typedef typename vector<T,Allocator>::iterator iterator;
        typedef typename vector<T,Allocator>::const_iterator const_iterator;
        explicit vector_async(){}

        /* disabled methods, sync mode only (throw) */

        /* from vector.h */
        /* vector(size_t n, T value = T());
           vector(const vector& a);
           vector& operator = (const vector& rhs);
           template<class OtherAllocator>
           vector& operator = (const vector<T,OtherAllocator>& rhs);
           
           void init(T value);
           void auto_reserve();*/

        virtual void reserve(size_t n);
        virtual void shrink_to_fit();
        virtual size_t measure() const;
        virtual void load() const;

        /* using immidiate size */

        virtual void swap(vector<T,Allocator>& r);
        virtual size_t size() const;
        virtual bool empty() const;
        virtual void resize(size_t sz);
        virtual void clear();

        /* using data-access */

        /* from vector.h */
        /* value_type* data();
           value_type& operator[](size_t i);
           value_type& at(size_type i);
           value_type& front();
           value_type& back();
           iterator begin();
           iterator end(); */

        virtual void push_back(value_type value);
        virtual void pop_back();
        virtual iterator insert(const_iterator position, value_type val);
        virtual iterator erase(const_iterator position);
    };

}

#endif

#ifndef BIND_CONTAINER_VECTOR_VECTOR_ASYNC_HPP
#define BIND_CONTAINER_VECTOR_VECTOR_ASYNC_HPP

namespace bind {

    /* disabled methods, sync mode only (throw) */

    template<class T, class Allocator>
    void vector_async<T,Allocator>::reserve(size_t sz){
        throw std::runtime_error("Error: can't realloc in async mode.");
    }

    template<class T, class Allocator>
    void vector_async<T,Allocator>::shrink_to_fit(){
        throw std::runtime_error("Error: can't realloc in async mode.");
    }

    template<class T, class Allocator>
    size_t vector_async<T,Allocator>::measure() const {
        throw std::runtime_error("Error: can't measure in async mode.");
    }

    template<typename T, class Allocator>
    void vector_async<T,Allocator>::load() const {
        throw std::runtime_error("Error: can't load in async mode.");
    }

    /* using immidiate size */

    template<class T, class Allocator>
    void vector_async<T,Allocator>::swap(vector<T,Allocator>& r){
        std::swap(this->bind_allocator.after->data, r.bind_allocator.after->data);
    }

    template<class T, class Allocator>
    size_t vector_async<T,Allocator>::size() const {
        return bind::delegated(*this).size_;
    }

    template<class T, class Allocator>
    bool vector_async<T,Allocator>::empty() const {
        return (size() == 0);
    }

    template<class T, class Allocator>
    void vector_async<T,Allocator>::resize(size_t sz){
        bind::delegated(*this).size_ = sz;
    }

    template<typename T, class Allocator>
    void vector_async<T,Allocator>::clear(){
        this->resize(0);
    }

    /* using data-access */

    template<class T, class Allocator>
    void vector_async<T,Allocator>::push_back(value_type value){
        if(this->size() == this->capacity()) printf("Capacity overflow!\n");
        (*this)[size()] = value;
        resize(size()+1);
    }

    template<class T, class Allocator>
    void vector_async<T,Allocator>::pop_back(){
        resize(size()-1);
    }

    template<typename T, class Allocator>
    typename vector_async<T,Allocator>::iterator vector_async<T,Allocator>::insert(const_iterator position, value_type val){
        for(int i = size(); i > (position-this->cbegin()); i--)
            (*this)[i] = (*this)[i-1];
        (*this)[position-this->cbegin()] = val;
        resize(size()+1);
        return (this->begin()+(position-this->cbegin()));
    }

    template<typename T, class Allocator>
    typename vector_async<T,Allocator>::iterator vector_async<T,Allocator>::erase(const_iterator position){
        for(int i = (position-this->cbegin()); i < size()-1; i++)
            (*this)[i] = (*this)[i+1];
        resize(size()-1);
        return (this->begin()+(position-this->cbegin()));
    }

}

#endif
// }}}
// {{{ bonus utils package (requires :*)

#ifndef BIND_UTILS_TIMER
#define BIND_UTILS_TIMER

namespace bind {

    void sync();
    class async_timer {
    public:
        async_timer(std::string name): val(0.0), name(name), count(0){}
       ~async_timer(){
            std::cout << "R" << bind::rank() << ": " << name << " " << val << ", count : " << count << "\n";
        }
        void begin(){
            this->t0 = std::chrono::system_clock::now();
        }
        void end(){
            this->val += std::chrono::duration<double>(std::chrono::system_clock::now() - this->t0).count();
            count++;
        }
        double get_time() const {
            return val;
        }
    private:
        double val;
        std::chrono::time_point<std::chrono::system_clock> t0;
        unsigned long long count;
        std::string name;
    };

    class timer : public async_timer {
    public:
        timer(std::string name) : async_timer(name){}
        void begin(){
            bind::sync();
            async_timer::begin();
        }
        void end(){
            bind::sync();
            async_timer::end();
        }
    };
}

#endif

// }}}
#ifdef BIND_NO_DEBUG
#undef NDEBUG
#endif
#endif
